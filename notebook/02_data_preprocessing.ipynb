{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from ZillowHouseData.logger import logger\n",
    "from ZillowHouseData.exception import CustomException\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    def __init__(self, file_name='ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv', start_date='2012-01-01'):\n",
    "        #self.file_name = file_name\n",
    "        #self.file_name = os.path.join('../','artifacts', 'data_ingestion',file_name)\n",
    "        self.file_name = os.path.join('..','artifacts', 'data_ingestion',file_name)\n",
    "        self.start_date = start_date\n",
    "\n",
    "    def data_preprocessing(self):\n",
    "        dtypes = {\n",
    "            'indicator_id': 'object',\n",
    "            'region_id': 'int32',\n",
    "            'value': 'float32',\n",
    "            'date': 'object'\n",
    "        }\n",
    "        df_list = []\n",
    "        count = 0\n",
    "\n",
    "        #raw_data_path: str=os.path.join('artifacts/data_ingestion/','ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv')\n",
    "        print(\"\\n printing os path current directory\")\n",
    "        print(os.getcwd())\n",
    "\n",
    "\n",
    "        file_path = os.path.join('artifacts', 'data_ingestion', 'ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv')\n",
    "        print(\"\\n printing file existance\")\n",
    "        print(os.path.exists(file_path))\n",
    "\n",
    "        \n",
    "        for chunk in pd.read_csv(self.file_name, chunksize=1000000,\n",
    "                                 usecols=['indicator_id', 'region_id', 'date', 'value'],\n",
    "                                 dtype=dtypes,\n",
    "                                 parse_dates=['date']):\n",
    "            filtered_chunk = chunk[(chunk['date'] >= self.start_date)]\n",
    "            df_list.append(filtered_chunk)\n",
    "\n",
    "        trimmed_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "        del df_list\n",
    "        \n",
    "        trimmed_data = pickle.dumps(trimmed_df)\n",
    "    \n",
    "        return trimmed_data\n",
    "\n",
    "    def get_year_month(self, data):\n",
    "        trimmed_df = pickle.loads(data)\n",
    "        trimmed_df['year'] = pd.to_datetime(trimmed_df['date']).dt.year\n",
    "        trimmed_df['month'] = pd.to_datetime(trimmed_df['date']).dt.month\n",
    "        trimmed_data = pickle.dumps(trimmed_df)\n",
    "        return trimmed_data\n",
    "\n",
    "    def get_stats(self, data):\n",
    "        trimmed_df = pickle.loads(data)\n",
    "        intersted_indicators_stats = ['IRAM', 'CRAM', 'MRAM', 'LRAM', 'NRAM', 'SRAM']\n",
    "        stat_df = trimmed_df[trimmed_df['indicator_id'].isin(intersted_indicators_stats)]\n",
    "        stat_pivot_df = stat_df.pivot_table(index=['region_id', 'year', 'month'], columns='indicator_id',\n",
    "                                           values='value', aggfunc='mean')\n",
    "        stat_pivot_df.reset_index(inplace=True)\n",
    "        stat_pivot_df.dropna(inplace=True)\n",
    "        stat_pivot_df.to_csv(\"stat.csv\")\n",
    "        del stat_df\n",
    "        trimmed_data = pickle.dumps(trimmed_df)\n",
    "        return trimmed_data\n",
    "\n",
    "    def get_merge(self, data):\n",
    "        trimmed_df = pickle.loads(data)\n",
    "        df = pd.read_csv('stat.csv')\n",
    "        intersted_indicators_ZHVI = ['ZATT', 'ZSFH', 'ZALL', 'ZCON', 'ZABT', 'Z2BR', 'Z5BR', 'Z3BR', 'Z1BR', 'Z4BR']\n",
    "        ZHVI_df = trimmed_df[trimmed_df['indicator_id'].isin(intersted_indicators_ZHVI)]\n",
    "        del trimmed_df\n",
    "        final_df = pd.merge(ZHVI_df, df, on=['region_id', 'year', 'month'], how='inner')\n",
    "        final_data = pickle.dumps(final_df)\n",
    "        final_df.to_csv(\"final.csv\")\n",
    "        return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZillowHouseData.components.data_preprocessing import DataPreprocessing\n",
    "from ZillowHouseData.logger import logger\n",
    "from ZillowHouseData.exception import CustomException\n",
    "from ZillowHouseData.config.configuration import ConfigurationManager\n",
    "from ZillowHouseData.pipeline.stage_01_data_ingestion_pipeline import ingestion_stage\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-10 20:32:28,322: INFO: 1457263588: >>>>>> stage Data Preprocessing stage initated <<<<<<\n",
      "\n",
      "x==========x]\n",
      "[2023-11-10 20:32:28,323: INFO: 1457263588: >>>>>> stage Data Preprocessing stage initated <<<<<<\n",
      "\n",
      "x==========x]\n",
      "\n",
      " printing os path current directory\n",
      "/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook\n",
      "\n",
      " printing file existance\n",
      "False\n",
      "[2023-11-10 20:32:28,325: ERROR: 1457263588: [Errno 2] No such file or directory: '. /artifacts/data_ingestion/ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv']\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/kp/6197l28d6yzb5wygdgr1hb7w0000gn/T/ipykernel_34285/1457263588.py\", line 33, in <module>\n",
      "    obj1.main()\n",
      "  File \"/var/folders/kp/6197l28d6yzb5wygdgr1hb7w0000gn/T/ipykernel_34285/1457263588.py\", line 14, in main\n",
      "    processed_data = data_preprocessor.data_preprocessing()\n",
      "  File \"/var/folders/kp/6197l28d6yzb5wygdgr1hb7w0000gn/T/ipykernel_34285/324563388.py\", line 28, in data_preprocessing\n",
      "    for chunk in pd.read_csv(self.file_name, chunksize=1000000,\n",
      "  File \"/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/common.py\", line 863, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '. /artifacts/data_ingestion/ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv'\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Error occured in python script name [/var/folders/kp/6197l28d6yzb5wygdgr1hb7w0000gn/T/ipykernel_34285/1457263588.py] line number [33] error message [[Errno 2] No such file or directory: '. /artifacts/data_ingestion/ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m obj1 \u001b[39m=\u001b[39m DataPreprocessingTrainingPipeline()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m obj1\u001b[39m.\u001b[39;49mmain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>>>>>> stage \u001b[39m\u001b[39m{\u001b[39;00mSTAGE_NAME\u001b[39m}\u001b[39;00m\u001b[39m completed <<<<<<\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mx==========x\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Replace 'your_data_bytes_here' with the actual data bytes you want to process\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#data = b'your_data_bytes_here'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Stage 1: Data Preprocessing\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m processed_data \u001b[39m=\u001b[39m data_preprocessor\u001b[39m.\u001b[39;49mdata_preprocessing()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Stage 2: Extract Year and Month\u001b[39;00m\n",
      "\u001b[1;32m/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(file_path))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_name, chunksize\u001b[39m=\u001b[39;49m\u001b[39m1000000\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                          usecols\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mindicator_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mregion_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                          dtype\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                          parse_dates\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     filtered_chunk \u001b[39m=\u001b[39m chunk[(chunk[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_date)]\n",
      "File \u001b[0;32m~/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m~/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m     \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m         handle,\n\u001b[1;32m    865\u001b[0m         ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m         encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m         newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m     )\n\u001b[1;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[39m# Binary mode\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '. /artifacts/data_ingestion/ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     logger\u001b[39m.\u001b[39mexception(e)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook/02_data_preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CustomException(e,sys)\n",
      "\u001b[0;31mCustomException\u001b[0m: Error occured in python script name [/var/folders/kp/6197l28d6yzb5wygdgr1hb7w0000gn/T/ipykernel_34285/1457263588.py] line number [33] error message [[Errno 2] No such file or directory: '. /artifacts/data_ingestion/ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv']"
     ]
    }
   ],
   "source": [
    "STAGE_NAME = \"Data Preprocessing stage\"\n",
    "\n",
    "class DataPreprocessingTrainingPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "            # Create an instance of the DataPreprocessing class\n",
    "            logger.info(f\">>>>>> stage {STAGE_NAME} initated <<<<<<\\n\\nx==========x\")\n",
    "            data_preprocessor = DataPreprocessing()\n",
    "            # Replace 'your_data_bytes_here' with the actual data bytes you want to process\n",
    "            #data = b'your_data_bytes_here'\n",
    "            # Stage 1: Data Preprocessing\n",
    "            processed_data = data_preprocessor.data_preprocessing()\n",
    "            # Stage 2: Extract Year and Month\n",
    "            logger.info(f\">>>>>> exact year & month <<<<<<\\n\\nx==========x\")\n",
    "            processed_data = data_preprocessor.get_year_month(processed_data)\n",
    "            # Stage 3: Get Stats\n",
    "            logger.info(f\">>>>>> get stats <<<<<<\\n\\nx==========x\")\n",
    "            processed_data = data_preprocessor.get_stats(processed_data)\n",
    "            # Stage 4: Merge Data\n",
    "            logger.info(f\">>>>>> merging data <<<<<<\\n\\nx==========x\")\n",
    "            final_data = data_preprocessor.get_merge(processed_data)\n",
    "            print(final_data)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #ingestion_stage()\n",
    "    try:\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} initated <<<<<<\\n\\nx==========x\")\n",
    "        obj1 = DataPreprocessingTrainingPipeline()\n",
    "        obj1.main()\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise CustomException(e,sys)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook\n"
     ]
    }
   ],
   "source": [
    "file_name = 'ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv'\n",
    "file = os.path.join('..','artifacts', 'data_ingestion',file_name)\n",
    "print(os.path.exists(file))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/mlops_zillow/lib/python3.10/site-packages\n",
      "File exists: False\n",
      "Current working directory: /Users/keshavkumarelankovan/Desktop/ML_OPS/Skirmish/Zillow-data-ML-project/notebook\n"
     ]
    }
   ],
   "source": [
    "file_name = 'ZILLOW_DATA_962c837a6ccefddddf190101e0bafdaf.csv'\n",
    "#script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "script_dir = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "print(script_dir)\n",
    "file_relative_path = os.path.join(script_dir, '..','artifacts', 'data_ingestion', file_name)\n",
    "\n",
    "# Check if the file exists\n",
    "print(\"File exists:\", os.path.exists(file_relative_path))\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn\n",
    "# !pip install pandas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "# label_encoder = LabelEncoder()\n",
    "df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project/artifacts/data_ingestion/final.csv')\n",
    "# Fit and transform the 'indicator_id' column\n",
    "# df['indicator_id'] = label_encoder.fit_transform(df['indicator_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>CRAM</th>\n",
       "      <th>IRAM</th>\n",
       "      <th>LRAM</th>\n",
       "      <th>MRAM</th>\n",
       "      <th>NRAM</th>\n",
       "      <th>SRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZATT</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>247142.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZSFH</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>143910.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZALL</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>142059.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ZCON</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>116574.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ZABT</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>77253.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303915</th>\n",
       "      <td>303915</td>\n",
       "      <td>Z5BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>742851.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303916</th>\n",
       "      <td>303916</td>\n",
       "      <td>Z2BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>334812.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303917</th>\n",
       "      <td>303917</td>\n",
       "      <td>Z3BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>435978.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303918</th>\n",
       "      <td>303918</td>\n",
       "      <td>Z1BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>388806.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303919</th>\n",
       "      <td>303919</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>559503.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303920 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 indicator_id  region_id        date     value  year  month  \\\n",
       "0                0         ZATT     394521  2020-06-30  247142.0  2020      6   \n",
       "1                1         ZSFH     394521  2020-06-30  143910.0  2020      6   \n",
       "2                2         ZALL     394521  2020-06-30  142059.0  2020      6   \n",
       "3                3         ZCON     394521  2020-06-30  116574.0  2020      6   \n",
       "4                4         ZABT     394521  2020-06-30   77253.0  2020      6   \n",
       "...            ...          ...        ...         ...       ...   ...    ...   \n",
       "303915      303915         Z5BR     395237  2022-09-30  742851.0  2022      9   \n",
       "303916      303916         Z2BR     395237  2022-09-30  334812.0  2022      9   \n",
       "303917      303917         Z3BR     395237  2022-09-30  435978.0  2022      9   \n",
       "303918      303918         Z1BR     395237  2022-09-30  388806.0  2022      9   \n",
       "303919      303919         Z4BR     395237  2022-09-30  559503.0  2022      9   \n",
       "\n",
       "           CRAM    IRAM      LRAM  MRAM  NRAM      SRAM  \n",
       "0       0.14970  2210.0  208990.0  25.0   4.0  158400.0  \n",
       "1       0.14970  2210.0  208990.0  25.0   4.0  158400.0  \n",
       "2       0.14970  2210.0  208990.0  25.0   4.0  158400.0  \n",
       "3       0.14970  2210.0  208990.0  25.0   4.0  158400.0  \n",
       "4       0.14970  2210.0  208990.0  25.0   4.0  158400.0  \n",
       "...         ...     ...       ...   ...   ...       ...  \n",
       "303915  0.18595   228.0  226450.0  18.0   7.0  334000.0  \n",
       "303916  0.18595   228.0  226450.0  18.0   7.0  334000.0  \n",
       "303917  0.18595   228.0  226450.0  18.0   7.0  334000.0  \n",
       "303918  0.18595   228.0  226450.0  18.0   7.0  334000.0  \n",
       "303919  0.18595   228.0  226450.0  18.0   7.0  334000.0  \n",
       "\n",
       "[303920 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 'ZATT', 9: 'ZSFH', 6: 'ZALL', 8: 'ZCON', 5: 'ZABT', 4: 'Z5BR', 1: 'Z2BR', 2: 'Z3BR', 0: 'Z1BR', 3: 'Z4BR'}\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder instance\n",
    "# label_encoder = LabelEncoder()\n",
    "# df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project/artifacts/data_ingestion/final.csv')\n",
    "\n",
    "# # Fit and transform the 'indicator_id' column\n",
    "df['encoded_indicator_id'] = label_encoder.fit_transform(df['indicator_id'])\n",
    "\n",
    "# Create a mapping dictionary to store the label-to-category mapping\n",
    "label_to_category_mapping = dict(zip(df['encoded_indicator_id'], df['indicator_id']))\n",
    "\n",
    "# Print the mapping\n",
    "print(label_to_category_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 'ZATT',\n",
       " 9: 'ZSFH',\n",
       " 6: 'ZALL',\n",
       " 8: 'ZCON',\n",
       " 5: 'ZABT',\n",
       " 4: 'Z5BR',\n",
       " 1: 'Z2BR',\n",
       " 2: 'Z3BR',\n",
       " 0: 'Z1BR',\n",
       " 3: 'Z4BR'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/final.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_indicator_id'] = label_encoder.fit_transform(df['indicator_id'])\n",
    "label_to_category_mapping = dict(zip(df['encoded_indicator_id'], df['indicator_id']))\n",
    "label_to_category_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/final.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_indicator_id'] = label_encoder.fit_transform(df['indicator_id'])\n",
    "label_to_category_mapping = dict(zip(df['encoded_indicator_id'], df['indicator_id']))\n",
    "df.drop(['Unnamed: 0','indicator_id'], axis=1, inplace= True)\n",
    "\n",
    "# Select relevant columns\n",
    "columns_to_use = ['encoded_indicator_id', 'region_id', 'year', 'month', 'CRAM', 'IRAM', 'LRAM', 'MRAM', 'NRAM', 'SRAM']\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[columns_to_use]\n",
    "y = df['value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_indicator_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>CRAM</th>\n",
       "      <th>IRAM</th>\n",
       "      <th>LRAM</th>\n",
       "      <th>MRAM</th>\n",
       "      <th>NRAM</th>\n",
       "      <th>SRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278515</th>\n",
       "      <td>5</td>\n",
       "      <td>753869</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>0.175799</td>\n",
       "      <td>441.0</td>\n",
       "      <td>194900.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>195000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39033</th>\n",
       "      <td>3</td>\n",
       "      <td>753869</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>283.0</td>\n",
       "      <td>237500.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253014</th>\n",
       "      <td>9</td>\n",
       "      <td>394308</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>0.104285</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>279777.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>286000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226918</th>\n",
       "      <td>7</td>\n",
       "      <td>394579</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>0.200238</td>\n",
       "      <td>927.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>174000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177475</th>\n",
       "      <td>5</td>\n",
       "      <td>394728</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>502.0</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>167500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218758</th>\n",
       "      <td>2</td>\n",
       "      <td>753877</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>0.132505</td>\n",
       "      <td>492.0</td>\n",
       "      <td>449000.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117867</th>\n",
       "      <td>6</td>\n",
       "      <td>394729</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>0.197927</td>\n",
       "      <td>963.0</td>\n",
       "      <td>149900.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>115000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269960</th>\n",
       "      <td>8</td>\n",
       "      <td>394418</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>115.0</td>\n",
       "      <td>516950.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>475000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225870</th>\n",
       "      <td>6</td>\n",
       "      <td>394619</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>397500.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>360000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82552</th>\n",
       "      <td>0</td>\n",
       "      <td>394668</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.150905</td>\n",
       "      <td>517.0</td>\n",
       "      <td>249900.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>195500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60784 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        encoded_indicator_id  region_id  year  month      CRAM    IRAM  \\\n",
       "278515                     5     753869  2022      8  0.175799   441.0   \n",
       "39033                      3     753869  2023      5  0.166667   283.0   \n",
       "253014                     9     394308  2022      4  0.104285  1745.0   \n",
       "226918                     7     394579  2021     11  0.200238   927.0   \n",
       "177475                     5     394728  2020     12  0.093074   502.0   \n",
       "...                      ...        ...   ...    ...       ...     ...   \n",
       "218758                     2     753877  2021      9  0.132505   492.0   \n",
       "117867                     6     394729  2019      8  0.197927   963.0   \n",
       "269960                     8     394418  2022      6  0.238095   115.0   \n",
       "225870                     6     394619  2021     11  0.122653  1814.0   \n",
       "82552                      0     394668  2018     10  0.150905   517.0   \n",
       "\n",
       "            LRAM  MRAM  NRAM      SRAM  \n",
       "278515  194900.0  13.0   5.0  195000.0  \n",
       "39033   237500.0  14.0   4.0  220000.0  \n",
       "253014  279777.0  21.0   6.0  286000.0  \n",
       "226918  175000.0  22.0   8.0  174000.0  \n",
       "177475  189900.0  58.0  26.0  167500.0  \n",
       "...          ...   ...   ...       ...  \n",
       "218758  449000.0  53.0  24.0  325000.0  \n",
       "117867  149900.0  49.0  31.0  115000.0  \n",
       "269960  516950.0  67.0  14.0  475000.0  \n",
       "225870  397500.0  22.0   8.0  360000.0  \n",
       "82552   249900.0  51.0  22.0  195500.0  \n",
       "\n",
       "[60784 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-2/artifacts/data_ingestion/filter_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI=https://dagshub.com/MurariHarish/Zillow-data-ML-project.mlflow \\\n",
    "MLFLOW_TRACKING_USERNAME=MurariHarish \\\n",
    "MLFLOW_TRACKING_PASSWORD=3ee01b477e66e78b2b9353669d56356fc4d4138c \\\n",
    "python script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/MurariHarish/Zillow-data-ML-project.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"MurariHarish\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"3ee01b477e66e78b2b9353669d56356fc4d4138c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MLFLOW_TRACKING_URI=https://dagshub.com/MurariHarish/Zillow-data-ML-project.mlflow\n",
    "export MLFLOW_TRACKING_USERNAME=MurariHarish\n",
    "export MLFLOW_TRACKING_PASSWORD=3ee01b477e66e78b2b9353669d56356fc4d4138c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_min_max(df):\n",
    "    \"\"\"Calculates the min and max values for each column in the training data.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): training data\n",
    "\n",
    "    Returns:\n",
    "        min_max_values (dict): min and max values for each column in the training data\n",
    "    \"\"\"\n",
    "    min_max_values = df.agg(['min', 'max']).to_dict()\n",
    "    return min_max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': {'min': 0, 'max': 303919},\n",
       " 'indicator_id': {'min': 'Z1BR', 'max': 'ZSFH'},\n",
       " 'region_id': {'min': 102001, 'max': 845167},\n",
       " 'date': {'min': '2018-01-31', 'max': '2023-07-31'},\n",
       " 'value': {'min': 20075.06, 'max': 5441841.0},\n",
       " 'year': {'min': 2018, 'max': 2023},\n",
       " 'month': {'min': 1, 'max': 12},\n",
       " 'CRAM': {'min': 0.0, 'max': 0.5},\n",
       " 'IRAM': {'min': 48.0, 'max': 1733389.0},\n",
       " 'LRAM': {'min': 44700.0, 'max': 2100000.0},\n",
       " 'MRAM': {'min': 6.0, 'max': 324.0},\n",
       " 'NRAM': {'min': 2.0, 'max': 324.0},\n",
       " 'SRAM': {'min': 36000.0, 'max': 1690000.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_min_max(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>66027</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>472191.62</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>558</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>97813</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>2146551.00</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>88825</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>304682.34</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1141</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>95909</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>469790.40</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>75872</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>425064.44</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 indicator_id  region_id        date       value  year  month\n",
       "0         265         Z4BR      66027  2022-07-31   472191.62  2022      7\n",
       "1         558         Z4BR      97813  2022-07-31  2146551.00  2022      7\n",
       "2         850         Z4BR      88825  2022-07-31   304682.34  2022      7\n",
       "3        1141         Z4BR      95909  2022-07-31   469790.40  2022      7\n",
       "4        1433         Z4BR      75872  2022-07-31   425064.44  2022      7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/filter_df.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>region_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>CRAM</th>\n",
       "      <th>IRAM</th>\n",
       "      <th>LRAM</th>\n",
       "      <th>MRAM</th>\n",
       "      <th>NRAM</th>\n",
       "      <th>SRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>102001</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147669</td>\n",
       "      <td>1491269.0</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>225000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>102001</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139205</td>\n",
       "      <td>1429228.0</td>\n",
       "      <td>264900.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>226000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>102001</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0.153135</td>\n",
       "      <td>1421529.0</td>\n",
       "      <td>269900.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>232000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>102001</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>0.162306</td>\n",
       "      <td>1500194.0</td>\n",
       "      <td>279000.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>235500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>102001</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>0.185487</td>\n",
       "      <td>1592415.0</td>\n",
       "      <td>281000.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>240000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  region_id  year  month      CRAM       IRAM      LRAM  MRAM  \\\n",
       "0          72     102001  2018      1  0.147669  1491269.0  255000.0  54.0   \n",
       "1          73     102001  2018      2  0.139205  1429228.0  264900.0  52.0   \n",
       "2          74     102001  2018      3  0.153135  1421529.0  269900.0  48.0   \n",
       "3          75     102001  2018      4  0.162306  1500194.0  279000.0  44.0   \n",
       "4          76     102001  2018      5  0.185487  1592415.0  281000.0  43.0   \n",
       "\n",
       "   NRAM      SRAM  \n",
       "0  47.0  225000.0  \n",
       "1  25.0  226000.0  \n",
       "2  20.0  232000.0  \n",
       "3  18.0  235500.0  \n",
       "4  18.0  240000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/stats.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merge(self, df_stats, df_month_year):\n",
    "        try:\n",
    "            interested_indicators_ZHVI = self.interested_indicators_zhvi\n",
    "            ZHVI_df = df_month_year[df_month_year['indicator_id'].isin(interested_indicators_ZHVI)]\n",
    "            \n",
    "            final_df = pd.merge(ZHVI_df, df_stats, on=['region_id', 'year', 'month'], how='inner')\n",
    "            final_df.to_csv(self.final_csv_path)\n",
    "            logger.info(f\">>>>>> Saved final.csv to {self.final_csv_path} <<<<<<\\n\\nx==========x\")\n",
    "            return final_df\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "def test_get_merge():\n",
    "\n",
    "    # Create test DataFrame for stats\n",
    "    stats_data = {\n",
    "    'region_id': [102001, 102001],\n",
    "    'year': [2018, 2018],\n",
    "    'month': [1, 2],\n",
    "    'CRAM': [0.147669, 0.139205],\n",
    "    'IRAM': [1491269.0, 1429228.0],\n",
    "    'LRAM': [255000.0, 264900.0],\n",
    "    'MRAM': [54.0, 52.0],\n",
    "    'NRAM': [47.0, 25.0],\n",
    "    'SRAM': [225000.0, 226000.0]\n",
    "}\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "\n",
    "    # Create test DataFrame for month_year\n",
    "    month_year_data = {\n",
    "    'region_id': [102001, 102001],\n",
    "    'year': [2018, 2018],\n",
    "    'month': [1, 2],\n",
    "    'indicator_id': ['Z4BR', 'Z4BR'],\n",
    "    'value': [472191.62, 2146551.00]\n",
    "}\n",
    "\n",
    "    month_year_df = pd.DataFrame(month_year_data)\n",
    "\n",
    "    # Test get_merge\n",
    "    merged_df = get_merge(stats_df, month_year_df)\n",
    "    \n",
    "    assert not merged_df.empty\n",
    "    assert 'ZATT' in merged_df['indicator_id'].values\n",
    "    assert 'CRAM' in merged_df.columns\n",
    "    assert 'IRAM' in merged_df.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/ZILLOW_REGIONS_1a51d107db038a83ac171d604cb48d5b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         394521\n",
       "1         394521\n",
       "2         394521\n",
       "3         394521\n",
       "4         394521\n",
       "           ...  \n",
       "303915    395237\n",
       "303916    395237\n",
       "303917    395237\n",
       "303918    395237\n",
       "303919    395237\n",
       "Name: region_id, Length: 303920, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['region_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_type</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394401</td>\n",
       "      <td>metro</td>\n",
       "      <td>Boone, IA; IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274772</td>\n",
       "      <td>neigh</td>\n",
       "      <td>Northeast Dallas; TX; Dallas-Fort Worth-Arling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273698</td>\n",
       "      <td>neigh</td>\n",
       "      <td>Far North; TX; Dallas-Fort Worth-Arlington, TX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275473</td>\n",
       "      <td>neigh</td>\n",
       "      <td>Southeast Dallas; TX; Dallas-Fort Worth-Arling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196538</td>\n",
       "      <td>neigh</td>\n",
       "      <td>Murray Hill; NY; New York-Newark-Jersey City; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region_id region_type                                             region\n",
       "0     394401       metro                                      Boone, IA; IA\n",
       "1     274772       neigh  Northeast Dallas; TX; Dallas-Fort Worth-Arling...\n",
       "2     273698       neigh  Far North; TX; Dallas-Fort Worth-Arlington, TX...\n",
       "3     275473       neigh  Southeast Dallas; TX; Dallas-Fort Worth-Arling...\n",
       "4     196538       neigh  Murray Hill; NY; New York-Newark-Jersey City; ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region_merge = pd.merge(df, df_regions, on='region_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>CRAM</th>\n",
       "      <th>IRAM</th>\n",
       "      <th>LRAM</th>\n",
       "      <th>MRAM</th>\n",
       "      <th>NRAM</th>\n",
       "      <th>SRAM</th>\n",
       "      <th>encoded_indicator_id</th>\n",
       "      <th>region_type</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZATT</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>247142.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "      <td>7</td>\n",
       "      <td>metro</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZSFH</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>143910.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "      <td>9</td>\n",
       "      <td>metro</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZALL</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>142059.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "      <td>6</td>\n",
       "      <td>metro</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ZCON</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>116574.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "      <td>8</td>\n",
       "      <td>metro</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ZABT</td>\n",
       "      <td>394521</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>77253.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>208990.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>158400.0</td>\n",
       "      <td>5</td>\n",
       "      <td>metro</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303915</th>\n",
       "      <td>303915</td>\n",
       "      <td>Z5BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>742851.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>metro</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303916</th>\n",
       "      <td>303916</td>\n",
       "      <td>Z2BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>334812.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>metro</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303917</th>\n",
       "      <td>303917</td>\n",
       "      <td>Z3BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>435978.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>metro</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303918</th>\n",
       "      <td>303918</td>\n",
       "      <td>Z1BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>388806.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>metro</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303919</th>\n",
       "      <td>303919</td>\n",
       "      <td>Z4BR</td>\n",
       "      <td>395237</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>559503.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18595</td>\n",
       "      <td>228.0</td>\n",
       "      <td>226450.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>334000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>metro</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303920 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 indicator_id  region_id        date     value  year  month  \\\n",
       "0                0         ZATT     394521  2020-06-30  247142.0  2020      6   \n",
       "1                1         ZSFH     394521  2020-06-30  143910.0  2020      6   \n",
       "2                2         ZALL     394521  2020-06-30  142059.0  2020      6   \n",
       "3                3         ZCON     394521  2020-06-30  116574.0  2020      6   \n",
       "4                4         ZABT     394521  2020-06-30   77253.0  2020      6   \n",
       "...            ...          ...        ...         ...       ...   ...    ...   \n",
       "303915      303915         Z5BR     395237  2022-09-30  742851.0  2022      9   \n",
       "303916      303916         Z2BR     395237  2022-09-30  334812.0  2022      9   \n",
       "303917      303917         Z3BR     395237  2022-09-30  435978.0  2022      9   \n",
       "303918      303918         Z1BR     395237  2022-09-30  388806.0  2022      9   \n",
       "303919      303919         Z4BR     395237  2022-09-30  559503.0  2022      9   \n",
       "\n",
       "           CRAM    IRAM      LRAM  MRAM  NRAM      SRAM  encoded_indicator_id  \\\n",
       "0       0.14970  2210.0  208990.0  25.0   4.0  158400.0                     7   \n",
       "1       0.14970  2210.0  208990.0  25.0   4.0  158400.0                     9   \n",
       "2       0.14970  2210.0  208990.0  25.0   4.0  158400.0                     6   \n",
       "3       0.14970  2210.0  208990.0  25.0   4.0  158400.0                     8   \n",
       "4       0.14970  2210.0  208990.0  25.0   4.0  158400.0                     5   \n",
       "...         ...     ...       ...   ...   ...       ...                   ...   \n",
       "303915  0.18595   228.0  226450.0  18.0   7.0  334000.0                     4   \n",
       "303916  0.18595   228.0  226450.0  18.0   7.0  334000.0                     1   \n",
       "303917  0.18595   228.0  226450.0  18.0   7.0  334000.0                     2   \n",
       "303918  0.18595   228.0  226450.0  18.0   7.0  334000.0                     0   \n",
       "303919  0.18595   228.0  226450.0  18.0   7.0  334000.0                     3   \n",
       "\n",
       "       region_type       region  \n",
       "0            metro   Dayton, OH  \n",
       "1            metro   Dayton, OH  \n",
       "2            metro   Dayton, OH  \n",
       "3            metro   Dayton, OH  \n",
       "4            metro   Dayton, OH  \n",
       "...            ...          ...  \n",
       "303915       metro  Wooster, OH  \n",
       "303916       metro  Wooster, OH  \n",
       "303917       metro  Wooster, OH  \n",
       "303918       metro  Wooster, OH  \n",
       "303919       metro  Wooster, OH  \n",
       "\n",
       "[303920 rows x 16 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_merge[df_region_merge['region_type'] == 'metro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_id</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303915</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303916</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303917</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303918</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303919</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        region_id       region\n",
       "0          394521   Dayton, OH\n",
       "1          394521   Dayton, OH\n",
       "2          394521   Dayton, OH\n",
       "3          394521   Dayton, OH\n",
       "4          394521   Dayton, OH\n",
       "...           ...          ...\n",
       "303915     395237  Wooster, OH\n",
       "303916     395237  Wooster, OH\n",
       "303917     395237  Wooster, OH\n",
       "303918     395237  Wooster, OH\n",
       "303919     395237  Wooster, OH\n",
       "\n",
       "[303920 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_merge[['region_id','region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_id</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394521</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394546</td>\n",
       "      <td>Dunn, NC; NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>395179</td>\n",
       "      <td>Utica, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394387</td>\n",
       "      <td>Binghamton, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394763</td>\n",
       "      <td>Lake Charles, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>845158</td>\n",
       "      <td>Dayton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>845160</td>\n",
       "      <td>Prescott Valley, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>845164</td>\n",
       "      <td>Lebanon, NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>845167</td>\n",
       "      <td>Ottawa, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>395237</td>\n",
       "      <td>Wooster, OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     region_id               region\n",
       "0       394521           Dayton, OH\n",
       "1       394546         Dunn, NC; NC\n",
       "2       395179            Utica, NY\n",
       "3       394387       Binghamton, NY\n",
       "4       394763     Lake Charles, LA\n",
       "..         ...                  ...\n",
       "707     845158           Dayton, OH\n",
       "708     845160  Prescott Valley, AZ\n",
       "709     845164          Lebanon, NH\n",
       "710     845167           Ottawa, IL\n",
       "711     395237          Wooster, OH\n",
       "\n",
       "[712 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regions = pd.read_csv('/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/ZILLOW_REGIONS_1a51d107db038a83ac171d604cb48d5b.csv')\n",
    "df_region_merge = pd.merge(df, df_regions, on='region_id', how='inner')\n",
    "df_region_merge[['region_id','region']].drop_duplicates(subset=['region_id', 'region']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_unique_regions(df):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, merges it with a given DataFrame on 'region_id',\n",
    "    extracts and sorts unique 'region_id' and 'region', and returns a dictionary for region_id to region lookup.\n",
    "\n",
    "    :param df: DataFrame to merge with the CSV data.\n",
    "    :return: Dictionary for region_id to region lookup.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_path = '/Users/hm/Documents/Github_Projects/Zillow-data-ML-project-1/artifacts/data_ingestion/ZILLOW_REGIONS_1a51d107db038a83ac171d604cb48d5b.csv'\n",
    "\n",
    "    # Read CSV file\n",
    "    df_regions = pd.read_csv(csv_path)\n",
    "\n",
    "    # Merge the provided DataFrame with the CSV data\n",
    "    df_region_merge = pd.merge(df, df_regions, on='region_id', how='inner')\n",
    "\n",
    "    # Extract unique 'region_id' and 'region', and reset the index\n",
    "    unique_regions_df = df_region_merge[['region_id', 'region']].drop_duplicates(subset=['region_id', 'region'])\n",
    "\n",
    "    # Sort the DataFrame based on 'region'\n",
    "    sorted_unique_regions_df = unique_regions_df.sort_values(by='region').reset_index(drop=True)\n",
    "\n",
    "    # Convert sorted DataFrame to dictionary for region_id to region lookup\n",
    "    region_id_to_region = dict(zip(sorted_unique_regions_df['region_id'], sorted_unique_regions_df['region']))\n",
    "\n",
    "    return region_id_to_region\n",
    "\n",
    "# Usage example\n",
    "# df is your original DataFrame\n",
    "region_id_to_region = extract_unique_regions(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton, OH'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_id_to_region[394521]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_object(load_folder, file_name):\n",
    "    try:\n",
    "        # Create the full load path, including the \"artifacts/\" folder\n",
    "        load_path = os.path.join(\"artifacts\", load_folder, file_name)\n",
    "\n",
    "        # Load the model from the pickle file\n",
    "        with open(load_path, 'rb') as file:\n",
    "            loaded_model = pickle.load(file)\n",
    "\n",
    "        return loaded_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the model: {str(e)}\")\n",
    "\n",
    "def save_object_to_pickle(object_to_save, save_folder, file_name):\n",
    "    try:\n",
    "        # Create the full save path, including the \"artifacts/\" folder\n",
    "        save_path = os.path.join(\"artifacts\", save_folder, file_name)\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        # Save the trained model to a pickle file\n",
    "        with open(save_path, 'wb') as file:\n",
    "            pickle.dump(object_to_save, file)\n",
    "\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the model: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to artifacts/models/region_label\n"
     ]
    }
   ],
   "source": [
    "save_object_to_pickle(region_id_to_region, \"models\", 'region_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_zillow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
